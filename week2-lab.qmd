---
title: "EDS 223: week 2"
format: html
editor_options: 
  chunk_output_type: console
---

```{r}
# Loading necessary packages:

rm(list = ls())
library(sf) # for handling vector data
library(tmap) # for making maps
library(tidyverse) # because we love the tidyverse
library(spData) # preloaded spatial data
```

First, we create a geometry for London by supplying a point and coordinate reference system.
```{r}
# create st_point with longitude and latitude for London
# simple feature geometry

london_point <- st_point(c(0.1, 51.5))

# add coordinate reference system
# simple feature collection
london_geom <- st_sfc(london_point, crs = 4326)
```

Then, we supply some non-geographic attributes by creating a data frame with attributes about London.
```{r}
london_attrib <- data.frame(
  name = "London",
  temperature = 25,
  date = as.Date("2017-06-21")
)

# combine geometry and data frame
# simple feature object
london_sf <- st_sf(london_attrib, geometry = london_geom)
class(london_sf)
```

Looking at what the CRS looks like:
```{r}
st_crs(london_sf)

st_crs(london_sf)$IsGeographic

st_crs(london_sf)$proj4string
```

Now let's look at an existing sf object representing the countries of the world:
```{r}
world <- spData::world
class(world)
```

```{r}
dim(world)
names(world)
```

We can see that this object contains both spatial data (geom column) and attributes about those geometries. We can perform operations on the attribute data, just like we would with a normal data frame.
```{r}
summary(world$lifeExp)
```

The geometry column is "sticky", meaning it will stick around unless we explicitly get rid of it. For example, dplyr's select() function won't get rid of it. 
```{r}
world_df <- world %>%
  select(-geom) #doesn't actually remove the geom column

colnames(world_df) # geom still shows up as a column
```

To drop the geom column and convert this sf object into a data frame, we need to drop the geometry column using the st_drop_geometry()
```{r}
world_df <- st_drop_geometry(world)
class(world_df)
```

## Reprojecting Data

Creating a data frame of the location (using a PCS)
```{r}
london_proj = data.frame(x = 530000, y = 180000) %>% 
  st_as_sf(coords = c("x", "y"), crs = "EPSG:27700")
```

We can check the CRS of any data using the st_crs() function
```{r}
st_crs(london_proj) == st_crs(london_sf)
# important to build in checks to make sure the coordinate reference systems match
```

To transform the CRS of a dataset, we use the st_transform() function. In the crs argument, we need to specify the coordinate reference system. We can do this by either supplying a CRS code or specifying the CRS of another dataset by using the st_crs() function
```{r}
london_sf_transform <- st_transform(london_sf, crs = st_crs(london_proj))
```

Now if we check, the CRS between the two datasets should match
```{r}
if(st_crs(london_sf_transform) == st_crs(london_proj)){
  print("it's a match!")
} else {
  warning("coordinate reference systems do not match")
}
# building in warning messages like this are great for workflow in your homework
```

## Changing map projections

Equal Earth projection: equal-area psuedocylindrical projection
```{r}
tm_shape(world, projection = 8857) +
  tm_fill(col = "area_km2")
```

Mercator: conformal cylindrical map that preserves angles
```{r}
tm_shape(world, projection = 3396) +
  tm_fill(col = "area_km2")
```


```{r}
tm_shape(world, projection = 3395) +
  tm_fill(col = "area_km2")
```

## Vector attribute subsetting

We can select columns
```{r}
world %>%
  select(name_long, pop)
```

or remove columns
```{r}
world %>%
  select(-subregion, -area_km2)
```

or select AND rename columns
```{r}
world %>%
  select(name = name_long, population = pop)
```

or filter based on variables
```{r}
world1 <- world %>%
  filter(area_km2 < 10000)

summary(world1$area_km2)
```

## Chaining commands with pipes
```{r}
world %>%
  filter(continent == "Asia") %>%
  select(name_long, continent, lifeExp) %>%
  slice_max(lifeExp) %>%
  st_drop_geometry()
```

## Vector attribute aggregation

summarizing data with one or more "grouping" variables
```{r}
world %>%
  group_by(continent) %>%
  summarize(population = sum(pop, na.rm = TRUE)) %>%
  st_drop_geometry()
```

## Joins with vector attributes
```{r}
coffee_data <- spData::coffee_data
head(coffee_data)
```

```{r}
world_coffee <- left_join(world, coffee_data, by = "name_long")
```

```{r}
tm_shape(world_coffee) +
  tm_fill(col = "coffee_production_2017")
```

```{r}
world_coffee_inner <- inner_join(world, coffee_data, by = "name_long")

if(nrow(world_coffee_inner) < nrow(coffee_data)) {
  warning("inner join does not match original data. potential data loss during join")
}
```

We can find rows that don't match using the setdiff() function.
```{r}
setdiff(coffee_data$name_long, world$name_long)
```
We see from this that one of the issues is that the two data sets use different naming conventions for the Democratic Republic of the Congo. We can use a string matching fucntion to figure out what the DCR is called in the world data set.
```{r}
# search for the DRC in the world dataset
drc <- stringr::str_subset(world$name_long, "Dem*.+Congo")

# then we can update the coffee data set with the matching name for the DRC
coffee_data$name_long[stringr::str_detect(coffee_data$name_long, "Congo")] <- drc
```

And we can try the inner join again and hopefully the DRC now matches:
```{r}
world_coffee_inner <- inner_join(world, coffee_data , by = "name_long")

# update warning message conditional to include the mismatch for "others"
if (nrow(world_coffee_inner) != nrow(coffee_data) & setdiff(coffee_data$name_long, world_coffee_inner$name_long) != "Others") {
  warning("inner join does not match original data. potential data loss during join")
}
```

Now, let's visualize what the inner join did to our spatial object
```{r}
tm_shape(world_coffee_inner) +
  tm_polygons(fill = "coffee_production_2017",
              title = "Coffee production (2017)") +
  tm_layout(legend.outside = TRUE)
```

critical thinking question:
what would happen if we left join a sf object onto a data frame?

- we get a data frame. if you want the spatial information, you need to go "onto" the dataset

